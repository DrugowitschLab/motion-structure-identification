# Motion structure identification in visual perception

Taking a normative Bayesian perspective on the visual perception of motion structure, this project investigates if and how human observers can identify statistical motion relations in dynamic scenes when all other stimulus features are uninformative. Having an ideal observer model at hand, we can quantitatively assess human motion structure perception when presented scenes are stochastic and potentially ambiguous. The study can contribute to our understanding of the visual integration of unreliable cues as well as on latent motion priors underlying human perception.

What had started as a summer project, meanwhile has grown up to become a preprint on bioRxiv:

**Sichao Yang, Johannes Bill, Jan Drugowitsch, and Sam Gershman**  
*Human visual motion perception shows hallmarks of Bayesian structural inference*

Abstract:
Motion relations in visual scenes carry an abundance of behaviorally relevant information, but little is known about the computations underlying the identification of visual motion structure by humans. We addressed this gap in two psychophysics experiments and found that participants identified hierarchically organized motion relations in close correspondence with Bayesian structural inference. We demonstrate that, for our tasks, a choice model based on the Bayesian ideal observer can accurately match many facets of human structural inference, including task performance, perceptual error patterns, single-trial responses, participant-specific differences, and subjective decision confidence, particularly when motion scenes are ambiguous. Our work can guide future neuroscience experiments to reveal the neural mechanisms underlying higher-level visual motion perception.

Resources:
This repository contains the code for the psychophysics experiments, the data analysis and plotting, as well as the raw data.

